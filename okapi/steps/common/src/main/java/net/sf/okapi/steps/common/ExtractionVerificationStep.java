/*===========================================================================
  Copyright (C) 2011 by the Okapi Framework contributors
-----------------------------------------------------------------------------
  This library is free software; you can redistribute it and/or modify it 
  under the terms of the GNU Lesser General Public License as published by 
  the Free Software Foundation; either version 2.1 of the License, or (at 
  your option) any later version.

  This library is distributed in the hope that it will be useful, but 
  WITHOUT ANY WARRANTY; without even the implied warranty of 
  MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the GNU Lesser 
  General Public License for more details.

  You should have received a copy of the GNU Lesser General Public License 
  along with this library; if not, write to the Free Software Foundation, 
  Inc., 59 Temple Place, Suite 330, Boston, MA 02111-1307 USA

  See also the full LGPL text here: http://www.gnu.org/copyleft/lesser.html
===========================================================================*/

package net.sf.okapi.steps.common;

import java.io.File;
import java.util.ArrayList;
import java.util.logging.Logger;

import net.sf.okapi.common.Event;
import net.sf.okapi.common.IParameters;
import net.sf.okapi.common.UsingParameters;
import net.sf.okapi.common.Util;
import net.sf.okapi.common.filters.IFilter;
import net.sf.okapi.common.filters.IFilterConfigurationMapper;
import net.sf.okapi.common.filterwriter.IFilterWriter;
import net.sf.okapi.common.pipeline.BasePipelineStep;
import net.sf.okapi.common.pipeline.annotations.StepParameterMapping;
import net.sf.okapi.common.pipeline.annotations.StepParameterType;
import net.sf.okapi.common.resource.RawDocument;
import net.sf.okapi.common.resource.StartSubDocument;

/**
 * Verifies if a {@link RawDocument} is extracted and merged back properly.
 * This step performs a first extraction, merges the result without changing
 * the data, then re-exact the file generated by the merge, and compare the event
 * generated in both extraction. There should be no difference.
 * <p>This verification does not verify that the merge file is valid, but it
 * should catch most of the problems caused by invalid merges.
 */
@UsingParameters(ExtractionVerificationStepParameters.class) // No parameters
public class ExtractionVerificationStep extends BasePipelineStep {

	private static final Logger LOGGER = Logger.getLogger(ExtractionVerificationStep.class.getName());
	
	private IFilter filter;
	private IFilterWriter writer;
	private IFilterConfigurationMapper fcMapper;
	private String filterConfigId;
	private ExtractionVerificationStepParameters params;
	
	/**
	 * Creates a new ExtractionVerificationStep object. This constructor is
	 * needed to be able to instantiate an object from newInstance()
	 */
	public ExtractionVerificationStep() {
		params = new ExtractionVerificationStepParameters();
	}
	
	@Override
	public void setParameters(IParameters params) {
		this.params = (ExtractionVerificationStepParameters) params;
	}
	
	@Override
	public ExtractionVerificationStepParameters getParameters() {
		return params;
	}
	
	@StepParameterMapping(parameterType = StepParameterType.FILTER_CONFIGURATION_MAPPER)
	public void setFilterConfigurationMapper (IFilterConfigurationMapper fcMapper) {
		this.fcMapper = fcMapper;
	}
	
	@StepParameterMapping(parameterType = StepParameterType.FILTER_CONFIGURATION_ID)
	public void setFilterConfigurationId (String filterConfigId) {
		this.filterConfigId = filterConfigId;
	}
	
	public String getName () {
		return "Extraction Verification";
	}

	public String getDescription () {
		return "Verifies a raw document can be extracted, merged, then extracted again and produces the same set of events during both extractions."
			+ " Expects: raw document. Sends back: unmodified raw document.";
	}

	@Override
	protected Event handleRawDocument (Event event) {
		
		try {
			if ( Util.isEmpty(filterConfigId) ) {
				return event;
			}
			// Else: Get the filter to use
			filter = fcMapper.createFilter(filterConfigId, filter);
			if (filter == null) {
				throw new RuntimeException("Unsupported filter type.");
			}
			
			//=== First extraction
			
			RawDocument initialDoc = event.getRawDocument();
			// Open the document
			filter.open(initialDoc);
			// Create the filter and write out the document 
			writer = filter.createFilterWriter();
			// Open the output document
			File outFile = File.createTempFile("okp-vx_", ".tmp");
			outFile.deleteOnExit();
			writer.setOutput(outFile.getAbsolutePath());
			writer.setOptions(initialDoc.getSourceLocale(), initialDoc.getEncoding());
			// Re-write the file from the extracted events
			ArrayList<Event> firstEvents = new ArrayList<Event>();
			Event event1;
			while ( filter.hasNext() ) {
				event1 = filter.next();
				firstEvents.add(event1);
				writer.handleEvent(event1);
			}
			writer.close();
			filter.close();

			
			//=== Second pass: Extract from the merged file and compare
			
			RawDocument tmpDoc = new RawDocument(outFile.toURI(), initialDoc.getEncoding(), initialDoc.getSourceLocale());
			filter.open(tmpDoc);
			Event event2;
			int i = 0;
			while ( filter.hasNext() ) {
				event2 = filter.next();
			
				if ( i >= firstEvents.size() ) {
					i++;
					break;
				}
				event1 = firstEvents.get(i++);
				// Compare events
				if ( !identicalEvent(event1, event2) ) {
					// TODO log error
					LOGGER.info("different events");
					break;
				}else{
					//LOGGER.info("identical events");
				}
			}
			
			// Compare total number of events
			if(firstEvents.size() > i){
				LOGGER.warning("Additional events found in the first run");
			}else if(i > firstEvents.size()){
				LOGGER.warning("Additional events found in the second run");
			}
			
		}
		catch ( Throwable e ) {
			throw new RuntimeException("Error during extraction verification.\n" + e.getMessage(), e);
		}
		finally {
			closeFilterAndWriter();
		}

		return event; // Return the original document
	}

	private void closeFilterAndWriter () {
		if ( writer != null ) {
			writer.close();
			writer = null;
		}
		if ( filter != null ) {
			filter.close();
			filter = null;
		}
	}

	public void destroy () {
		closeFilterAndWriter();
	}

	public void cancel () {
		if ( filter != null ) filter.cancel();
	}

	private boolean identicalEvent (Event event1,
		Event event2)
	{
		if (( event1 == null ) && ( event2 != null )) {
			LOGGER.warning("Event from first run is null");
			return false;
		}
		if (( event1 != null ) && ( event2 == null )) {
			LOGGER.warning("Event from second run is null");
			return false;
		}
		if (( event1 == null ) && ( event2 == null )) {
			return true; // They are the same
		}

		if ( event1.getEventType() != event2.getEventType() ) {
			LOGGER.warning("Event Types are different");
			return false;
		}

		ExtractionVerificationUtil verificationUtil = new ExtractionVerificationUtil();
		
		switch ( event1.getEventType() ) {
		case START_DOCUMENT:
			break;
		case START_SUBDOCUMENT:
			return verificationUtil.compareStartSubDocument((StartSubDocument)event1.getResource(), (StartSubDocument)event2.getResource());
		case START_GROUP:
			return verificationUtil.compareBaseReferenceable(event1.getStartGroup(), event2.getStartGroup());
		case END_DOCUMENT:
		case END_SUBDOCUMENT:
		case END_GROUP:
			return verificationUtil.compareIResources(event1.getEnding(), event2.getEnding());
		case DOCUMENT_PART:
			return verificationUtil.compareBaseReferenceable(event1.getDocumentPart(), event2.getDocumentPart());
		case TEXT_UNIT:
			return verificationUtil.compareTextUnits(event1.getTextUnit(), event2.getTextUnit());
		}
		
		return true;
	}
}
